{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "posted-transportation",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import json\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import pandas as pd\n",
    "\n",
    "from tensorflow.python.keras.models import load_model\n",
    "from tensorflow.python.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "import spacy\n",
    "from spacy.language import Language\n",
    "from spacy.pipeline import EntityRuler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "worldwide-theorem",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_system():\n",
    "    \n",
    "    #Load Responses\n",
    "    print('Loading Responses...')\n",
    "    with open(\"intents.json\") as file:\n",
    "        pattern = json.load(file)\n",
    "    responses = pattern['responses']\n",
    "    \n",
    "    #Load Intent Model    \n",
    "    print('Loading Intent Model...')\n",
    "    model = load_model('intent_model/intents.h5')\n",
    "    with open('intent_model/classes.pkl','rb') as file:\n",
    "        classes = pickle.load(file)\n",
    "    with open('intent_model/tokenizer.pkl','rb') as file:\n",
    "        tokenizer = pickle.load(file)\n",
    "    with open('intent_model/label_encoder.pkl','rb') as file:\n",
    "        label_encoder = pickle.load(file)\n",
    "\n",
    "    #Load Knowledge Graph\n",
    "    print('Loading Knowledge Graph...')\n",
    "    Graph = nx.read_gexf(\"Knowledge_Graph.gexf\")    \n",
    "    \n",
    "    #Build Spacy NER  \n",
    "    print('Building NER...')\n",
    "    with open('ner_patterns.json') as f:\n",
    "        data = json.load(f)\n",
    "    \n",
    "    nlp = spacy.load(r'./spacy_model', exclude='ent_ruler')\n",
    "    \n",
    "    ruler = EntityRuler(nlp, overwrite_ents=True)\n",
    "    patterns = data\n",
    "    ruler.add_patterns(patterns)\n",
    "    \n",
    "    @Language.component('ent_ruler')\n",
    "    def ent_ruler(doc):\n",
    "        ruler(doc)\n",
    "        return doc\n",
    "    nlp.add_pipe('ent_ruler')\n",
    "    \n",
    "    print('== Done ==')\n",
    "    return responses, model, classes, tokenizer, label_encoder, Graph, nlp\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "everyday-spectacular",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Responses...\n",
      "Loading Intent Model...\n",
      "Loading Knowledge Graph...\n",
      "Building NER...\n",
      "== Done ==\n"
     ]
    }
   ],
   "source": [
    "responses, model, classes, tokenizer, label_encoder, Graph, nlp = initialize_system()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "voluntary-tracy",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_intent(text):\n",
    "    text = tokenizer.texts_to_sequences(text)\n",
    "    text = pad_sequences(text, maxlen=16, padding='post')\n",
    "    pred = model.predict(text)\n",
    "    if np.max(pred) < 0.6:\n",
    "        return 'none'\n",
    "    return label_encoder.inverse_transform(np.argmax(pred,1))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "center-sigma",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat():\n",
    "    \n",
    "    qa_intents = ['award', 'genre', 'cast', 'director', 'writer', 'producer', 'plot']\n",
    "    prev_title = ''\n",
    "    \n",
    "    while(True):\n",
    "        question = input('You:       ').lower()\n",
    "        response = ''\n",
    "\n",
    "        intent = get_intent([question])\n",
    "        \n",
    "        if intent == 'goodbye' or question.lower() == 'quit':\n",
    "            response = np.random.choice(responses[intent])\n",
    "            print('MovieMate:',response.format('deneme'))\n",
    "            break\n",
    "        \n",
    "        if intent not in qa_intents:\n",
    "            response = responses[intent]\n",
    "            response = np.random.choice(response)\n",
    "            print('MovieMate:',response.format('deneme'))\n",
    "            continue\n",
    "        else:\n",
    "            doc = nlp(question)\n",
    "            title = ''\n",
    "                        \n",
    "            for ent in doc.ents:\n",
    "                if ent.label_ == 'TTL':\n",
    "                    for j in doc:\n",
    "                        if j.dep_.find('obj') != -1 or j.dep_.find('subj') != -1:\n",
    "                            title = ent.text\n",
    "                            prev_title = title\n",
    "            \n",
    "            if title == '':\n",
    "                if prev_title != '':\n",
    "                    print('MovieMate:', 'Do you talking about {}'.format(prev_title))\n",
    "                    resp = input('You:       ').lower()\n",
    "                    if get_intent([resp]) == 'yes':\n",
    "                        title = prev_title\n",
    "                        print('Title :', title)\n",
    "                \n",
    "            try:\n",
    "                dict1 = dict(Graph[title])\n",
    "            except:\n",
    "                print('MovieMate:', 'I don\\'t understand which movie we are talking.')\n",
    "                continue\n",
    "\n",
    "            answer = []\n",
    "            content = ''\n",
    "            for i in dict1.keys():   \n",
    "                if dict1[i]['relation'] == intent:\n",
    "                    if intent in ['cast', 'director', 'writer', 'genre']:\n",
    "                        answer.append(i)                        \n",
    "                    else:\n",
    "                        content = Graph.nodes.data()[i]['content']\n",
    "                        response = content\n",
    "                        print('MovieMate:',response.format(answer))\n",
    "                        break\n",
    "            \n",
    "            if content == '':\n",
    "                if len(answer) == 0:\n",
    "                    print('MovieMate:',' Sorry, but i have no information about {0} of the {1}'.format(intent, title))\n",
    "                    continue\n",
    "                elif len(answer) == 1:\n",
    "                    answer = answer[0]\n",
    "                else:\n",
    "                    temp = ''\n",
    "                    for i in answer[:-1]:\n",
    "                        temp += str(i) + ', '\n",
    "                    temp += 'and '+ str(answer[-1])\n",
    "                    answer = temp\n",
    "            \n",
    "                response = responses[intent]\n",
    "                response = np.random.choice(response)\n",
    "                print('MovieMate:',response.format(answer))\n",
    "                continue\n",
    "        \n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "seeing-permission",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You:       hi\n",
      "MovieMate: Hi\n",
      "You:       how are you?\n",
      "MovieMate: Hi\n",
      "You:       goodbye\n",
      "MovieMate: Goodbye\n"
     ]
    }
   ],
   "source": [
    "chat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alternate-recall",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dying-sunday",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
